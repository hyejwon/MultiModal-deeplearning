{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc0604c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SHAPE: torch.Size([5, 1, 40, 128])\n",
      "BLOCK1 INPUT SHAPE: torch.Size([5, 16, 20, 128])\n",
      "BLOCK2 INPUT SHAPE: torch.Size([5, 8, 20, 128])\n",
      "BLOCK3 INPUT SHAPE: torch.Size([5, 12, 10, 128])\n",
      "BLOCK4 INPUT SHAPE: torch.Size([5, 16, 5, 128])\n",
      "Conv2 INPUT SHAPE: torch.Size([5, 20, 5, 128])\n",
      "Conv3 INPUT SHAPE: torch.Size([5, 20, 1, 128])\n",
      "Conv4 INPUT SHAPE: torch.Size([5, 32, 1, 1])\n",
      "OUTPUT SHAPE: torch.Size([5, 12, 1, 1])\n",
      "num parameters: 9160\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SubSpectralNorm(nn.Module):\n",
    "    def __init__(self, C, S, eps=1e-5):\n",
    "        super(SubSpectralNorm, self).__init__()\n",
    "        self.S = S\n",
    "        self.eps = eps\n",
    "        self.bn = nn.BatchNorm2d(C*S)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: input features with shape {N, C, F, T}\n",
    "        # S: number of sub-bands\n",
    "        N, C, F, T = x.size()\n",
    "        x = x.view(N, C * self.S, F // self.S, T)\n",
    "\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return x.view(N, C, F, T)\n",
    "\n",
    "\n",
    "class BroadcastedBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            planes: int,\n",
    "            dilation=1,\n",
    "            stride=1,\n",
    "            temp_pad=(0, 1),\n",
    "    ) -> None:\n",
    "        super(BroadcastedBlock, self).__init__()\n",
    "\n",
    "        self.freq_dw_conv = nn.Conv2d(planes, planes, kernel_size=(3, 1), padding=(1, 0), groups=planes,\n",
    "                                      dilation=dilation,\n",
    "                                      stride=stride, bias=False)\n",
    "        self.ssn1 = SubSpectralNorm(planes, 5)\n",
    "        self.temp_dw_conv = nn.Conv2d(planes, planes, kernel_size=(1, 3), padding=temp_pad, groups=planes,\n",
    "                                      dilation=dilation, stride=stride, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.channel_drop = nn.Dropout2d(p=0.5)\n",
    "        self.swish = nn.SiLU()\n",
    "        self.conv1x1 = nn.Conv2d(planes, planes, kernel_size=(1, 1), bias=False)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        # f2\n",
    "        ##########################\n",
    "        out = self.freq_dw_conv(x)\n",
    "        out = self.ssn1(out)\n",
    "        ##########################\n",
    "\n",
    "        auxilary = out\n",
    "        out = out.mean(2, keepdim=True)  # frequency average pooling\n",
    "\n",
    "        # f1\n",
    "        ############################\n",
    "        out = self.temp_dw_conv(out)\n",
    "        out = self.bn(out)\n",
    "        out = self.swish(out)\n",
    "        out = self.conv1x1(out)\n",
    "        out = self.channel_drop(out)\n",
    "        ############################\n",
    "\n",
    "        out = out + identity + auxilary\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransitionBlock(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            inplanes: int,\n",
    "            planes: int,\n",
    "            dilation=1,\n",
    "            stride=1,\n",
    "            temp_pad=(0, 1),\n",
    "    ) -> None:\n",
    "        super(TransitionBlock, self).__init__()\n",
    "\n",
    "        self.freq_dw_conv = nn.Conv2d(planes, planes, kernel_size=(3, 1), padding=(1, 0), groups=planes,\n",
    "                                      stride=stride,\n",
    "                                      dilation=dilation, bias=False)\n",
    "        self.ssn = SubSpectralNorm(planes, 5)\n",
    "        self.temp_dw_conv = nn.Conv2d(planes, planes, kernel_size=(1, 3), padding=temp_pad, groups=planes,\n",
    "                                      dilation=dilation, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.channel_drop = nn.Dropout2d(p=0.5)\n",
    "        self.swish = nn.SiLU()\n",
    "        self.conv1x1_1 = nn.Conv2d(inplanes, planes, kernel_size=(1, 1), bias=False)\n",
    "        self.conv1x1_2 = nn.Conv2d(planes, planes, kernel_size=(1, 1), bias=False)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # f2\n",
    "        #############################\n",
    "        out = self.conv1x1_1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.freq_dw_conv(out)\n",
    "        out = self.ssn(out)\n",
    "        #############################\n",
    "        auxilary = out\n",
    "        out = out.mean(2, keepdim=True)  # frequency average pooling\n",
    "\n",
    "        # f1\n",
    "        #############################\n",
    "        out = self.temp_dw_conv(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.swish(out)\n",
    "        out = self.conv1x1_2(out)\n",
    "        out = self.channel_drop(out)\n",
    "        #############################\n",
    "\n",
    "        out = auxilary + out\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class BCResNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BCResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, stride=(2, 1), padding=(2, 2))\n",
    "        self.block1_1 = TransitionBlock(16, 8)\n",
    "        self.block1_2 = BroadcastedBlock(8)\n",
    "\n",
    "        self.block2_1 = TransitionBlock(8, 12, stride=(2, 1), dilation=(1, 2), temp_pad=(0, 2))\n",
    "        self.block2_2 = BroadcastedBlock(12, dilation=(1, 2), temp_pad=(0, 2))\n",
    "\n",
    "        self.block3_1 = TransitionBlock(12, 16, stride=(2, 1), dilation=(1, 4), temp_pad=(0, 4))\n",
    "        self.block3_2 = BroadcastedBlock(16, dilation=(1, 4), temp_pad=(0, 4))\n",
    "        self.block3_3 = BroadcastedBlock(16, dilation=(1, 4), temp_pad=(0, 4))\n",
    "        self.block3_4 = BroadcastedBlock(16, dilation=(1, 4), temp_pad=(0, 4))\n",
    "\n",
    "        self.block4_1 = TransitionBlock(16, 20, dilation=(1, 8), temp_pad=(0, 8))\n",
    "        self.block4_2 = BroadcastedBlock(20, dilation=(1, 8), temp_pad=(0, 8))\n",
    "        self.block4_3 = BroadcastedBlock(20, dilation=(1, 8), temp_pad=(0, 8))\n",
    "        self.block4_4 = BroadcastedBlock(20, dilation=(1, 8), temp_pad=(0, 8))\n",
    "\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5, groups=20, padding=(0, 2))\n",
    "        self.conv3 = nn.Conv2d(20, 32, 1, bias=False)\n",
    "        self.conv4 = nn.Conv2d(32, 12, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        print('INPUT SHAPE:', x.shape)\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        print('BLOCK1 INPUT SHAPE:', out.shape)\n",
    "        out = self.block1_1(out)\n",
    "        out = self.block1_2(out)\n",
    "\n",
    "        print('BLOCK2 INPUT SHAPE:', out.shape)\n",
    "        out = self.block2_1(out)\n",
    "        out = self.block2_2(out)\n",
    "\n",
    "        print('BLOCK3 INPUT SHAPE:', out.shape)\n",
    "        out = self.block3_1(out)\n",
    "        out = self.block3_2(out)\n",
    "        out = self.block3_3(out)\n",
    "        out = self.block3_4(out)\n",
    "\n",
    "        print('BLOCK4 INPUT SHAPE:', out.shape)\n",
    "        out = self.block4_1(out)\n",
    "        out = self.block4_2(out)\n",
    "        out = self.block4_3(out)\n",
    "        out = self.block4_4(out)\n",
    "\n",
    "        print('Conv2 INPUT SHAPE:', out.shape)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        print('Conv3 INPUT SHAPE:', out.shape)\n",
    "        out = self.conv3(out)\n",
    "        out = out.mean(-1, keepdim=True)\n",
    "\n",
    "        print('Conv4 INPUT SHAPE:', out.shape)\n",
    "        out = self.conv4(out)\n",
    "\n",
    "        print('OUTPUT SHAPE:', out.shape)\n",
    "        return out\n",
    "\n",
    "\n",
    "x = torch.ones(5, 1, 40, 128)\n",
    "bcresnet = BCResNet()\n",
    "_ = bcresnet(x)\n",
    "print('num parameters:', sum(p.numel() for p in bcresnet.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3ba80865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "\n",
    "\n",
    "class SubSpectralNorm(nn.Module):\n",
    "    def __init__(self, C, S, eps=1e-5):\n",
    "        super(SubSpectralNorm, self).__init__()\n",
    "        self.S = S\n",
    "        self.eps = eps\n",
    "        self.bn = nn.BatchNorm2d(C*S)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: input features with shape {N, C, F, T}\n",
    "        # S: number of sub-bands\n",
    "        N, C, F, T = x.size()\n",
    "        x = x.view(N, C * self.S, F // self.S, T)\n",
    "\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return x.view(N, C, F, T)\n",
    "\n",
    "\n",
    "class BroadcastedBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            planes: int,\n",
    "            dilation=1,\n",
    "            stride=1,\n",
    "            temp_pad=(0, 1),\n",
    "    ) -> None:\n",
    "        super(BroadcastedBlock, self).__init__()\n",
    "\n",
    "        self.freq_dw_conv = nn.Conv2d(planes, planes, kernel_size=(3, 1), padding=(1, 0), groups=planes,\n",
    "                                      dilation=dilation,\n",
    "                                      stride=stride, bias=False)\n",
    "        self.ssn1 = SubSpectralNorm(planes, 5)\n",
    "        self.temp_dw_conv = nn.Conv2d(planes, planes, kernel_size=(1, 3), padding=temp_pad, groups=planes,\n",
    "                                      dilation=dilation, stride=stride, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.channel_drop = nn.Dropout2d(p=0.5)\n",
    "        self.swish = nn.SiLU()\n",
    "        self.conv1x1 = nn.Conv2d(planes, planes, kernel_size=(1, 1), bias=False)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        # f2\n",
    "        ##########################\n",
    "        out = self.freq_dw_conv(x)\n",
    "        out = self.ssn1(out)\n",
    "        ##########################\n",
    "\n",
    "        auxilary = out\n",
    "        out = out.mean(2, keepdim=True)  # frequency average pooling\n",
    "\n",
    "        # f1\n",
    "        ############################\n",
    "        out = self.temp_dw_conv(out)\n",
    "        out = self.bn(out)\n",
    "        out = self.swish(out)\n",
    "        out = self.conv1x1(out)\n",
    "        out = self.channel_drop(out)\n",
    "        ############################\n",
    "\n",
    "        out = out + identity + auxilary\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransitionBlock(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            inplanes: int,\n",
    "            planes: int,\n",
    "            dilation=1,\n",
    "            stride=1,\n",
    "            temp_pad=(0, 1),\n",
    "    ) -> None:\n",
    "        super(TransitionBlock, self).__init__()\n",
    "\n",
    "        self.freq_dw_conv = nn.Conv2d(planes, planes, kernel_size=(3, 1), padding=(1, 0), groups=planes,\n",
    "                                      stride=stride,\n",
    "                                      dilation=dilation, bias=False)\n",
    "        self.ssn = SubSpectralNorm(planes, 5)\n",
    "        self.temp_dw_conv = nn.Conv2d(planes, planes, kernel_size=(1, 3), padding=temp_pad, groups=planes,\n",
    "                                      dilation=dilation, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.channel_drop = nn.Dropout2d(p=0.5)\n",
    "        self.swish = nn.SiLU()\n",
    "        self.conv1x1_1 = nn.Conv2d(inplanes, planes, kernel_size=(1, 1), bias=False)\n",
    "        self.conv1x1_2 = nn.Conv2d(planes, planes, kernel_size=(1, 1), bias=False)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # f2\n",
    "        #############################\n",
    "        out = self.conv1x1_1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.freq_dw_conv(out)\n",
    "        out = self.ssn(out)\n",
    "        #############################\n",
    "        auxilary = out\n",
    "        out = out.mean(2, keepdim=True)  # frequency average pooling\n",
    "\n",
    "        # f1\n",
    "        #############################\n",
    "        out = self.temp_dw_conv(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.swish(out)\n",
    "        out = self.conv1x1_2(out)\n",
    "        out = self.channel_drop(out)\n",
    "        #############################\n",
    "\n",
    "        out = auxilary + out\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class BCResNet(torch.nn.Module):\n",
    "    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, \n",
    "        fmax):\n",
    "        super(BCResNet, self).__init__()\n",
    "        \n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
    "            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
    "            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "            freq_drop_width=8, freq_stripes_num=2)\n",
    "\n",
    "        #self.bn0 = nn.BatchNorm2d(40)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, stride=(2, 1), padding=(2, 2))\n",
    "        self.block1_1 = TransitionBlock(16, 8)\n",
    "        self.block1_2 = BroadcastedBlock(8)\n",
    "\n",
    "        self.block2_1 = TransitionBlock(8, 12, stride=(2, 1), dilation=(1, 2), temp_pad=(0, 2))\n",
    "        self.block2_2 = BroadcastedBlock(12, dilation=(1, 2), temp_pad=(0, 2))\n",
    "\n",
    "        self.block3_1 = TransitionBlock(12, 20, stride=(2, 1), dilation=(1, 4), temp_pad=(0, 4))\n",
    "        self.block3_2 = BroadcastedBlock(20, dilation=(1, 4), temp_pad=(0, 4))\n",
    "        self.block3_3 = BroadcastedBlock(20, dilation=(1, 4), temp_pad=(0, 4))\n",
    "        self.block3_4 = BroadcastedBlock(20, dilation=(1, 4), temp_pad=(0, 4))\n",
    "\n",
    "        self.block4_1 = TransitionBlock(16, 20, dilation=(1, 8), temp_pad=(0, 8))\n",
    "        self.block4_2 = BroadcastedBlock(20, dilation=(1, 8), temp_pad=(0, 8))\n",
    "        self.block4_3 = BroadcastedBlock(20, dilation=(1, 8), temp_pad=(0, 8))\n",
    "        self.block4_4 = BroadcastedBlock(20, dilation=(1, 8), temp_pad=(0, 8))\n",
    "\n",
    "        #self.conv2 = nn.Conv2d(20, 64, 5, groups=4, padding=(0, 2))\n",
    "        #self.conv3 = nn.Conv2d(64, 128, 1, bias=False)\n",
    "        #self.conv4 = nn.Conv2d(128, 256, 1, bias=False)\n",
    "        \n",
    "        self.conv_block1 = ConvBlock(in_channels=20, out_channels=64)\n",
    "        self.conv_block2 = ConvBlock(in_channels=64, out_channels=128)\n",
    "        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n",
    "        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n",
    "        self.fc1 = nn.Linear(512, 512, bias=True)\n",
    "        self.fc_audioset = nn.Linear(512, 527, bias=True)\n",
    "        \n",
    "    def init_weight(self):\n",
    "        #init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc_audioset)\n",
    "    \n",
    "    \n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        x = self.spectrogram_extractor(input)\n",
    "        \n",
    "        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        #x = self.bn0(x)\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        \n",
    "        x = x.transpose(2, 3)\n",
    "        \n",
    "        #if self.training:\n",
    "        #    x = self.spec_augmenter(x)\n",
    "\n",
    "        # Mixup on spectrogram\n",
    "        if self.training and mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "        \n",
    "        print('INPUT SHAPE:', x.shape)\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        print('BLOCK1 INPUT SHAPE:', out.shape)\n",
    "        out = self.block1_1(out)\n",
    "        out = self.block1_2(out)\n",
    "\n",
    "        print('BLOCK2 INPUT SHAPE:', out.shape)\n",
    "        out = self.block2_1(out)\n",
    "        out = self.block2_2(out)\n",
    "\n",
    "        print('BLOCK3 INPUT SHAPE:', out.shape)\n",
    "        out = self.block3_1(out)\n",
    "        out = self.block3_2(out)\n",
    "        out = self.block3_3(out)\n",
    "        out = self.block3_4(out)\n",
    "\n",
    "        #print('BLOCK4 INPUT SHAPE:', out.shape)\n",
    "        #out = self.block4_1(out)\n",
    "        #out = self.block4_2(out)\n",
    "        #out = self.block4_3(out)\n",
    "        #out = self.block4_4(out)\n",
    "\n",
    "        \n",
    "        x = self.conv_block1(out, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        \n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        print('Conv2 INPUT SHAPE:', out.shape)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        print('Conv3 INPUT SHAPE:', out.shape)\n",
    "        out = self.conv3(out)\n",
    "        #out = out.mean(-1, keepdim=True)\n",
    "\n",
    "        print('Conv4 INPUT SHAPE:', out.shape)\n",
    "        out = self.conv4(out)\n",
    "\n",
    "        print('OUTPUT SHAPE:', out.shape)\n",
    "        \n",
    "        \"\"\"\n",
    "        x = torch.mean(x, dim=3)\n",
    "        (x1, _) = torch.max(out, dim=2)\n",
    "        x2 = torch.mean(out, dim=2)\n",
    "        x = x1 + x2\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        out = F.relu_(self.fc1(x))\n",
    "        embedding = F.dropout(out, p=0.5, training=self.training)\n",
    "        clipwise_output = torch.sigmoid(self.fc_audioset(out))\n",
    "        output_dict = {'clipwise_output': clipwise_output, 'embedding': embedding}\n",
    "        #print('OUTPUT SHAPE:', out.shape)\n",
    "        return output_dict\n",
    "\n",
    "\n",
    "#x = torch.ones(5, 1, 40, 256)#(배치사이즈,인풋채널,인풋길이,w)\n",
    "#bcresnet = BCResNet()\n",
    "#_ = bcresnet(x)\n",
    "#print('num parameters:', sum(p.numel() for p in bcresnet.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ddb26b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BCResNet(sample_rate=32000, window_size=1024, \n",
    "        hop_size=320, mel_bins=40, fmin=50, fmax=14000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "78b4fdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCResNet(\n",
       "  (spectrogram_extractor): Spectrogram(\n",
       "    (stft): STFT(\n",
       "      (conv_real): Conv1d(1, 513, kernel_size=(1024,), stride=(320,), bias=False)\n",
       "      (conv_imag): Conv1d(1, 513, kernel_size=(1024,), stride=(320,), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (logmel_extractor): LogmelFilterBank()\n",
       "  (spec_augmenter): SpecAugmentation(\n",
       "    (time_dropper): DropStripes()\n",
       "    (freq_dropper): DropStripes()\n",
       "  )\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(2, 1), padding=(2, 2))\n",
       "  (block1_1): TransitionBlock(\n",
       "    (freq_dw_conv): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=8, bias=False)\n",
       "    (ssn): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=8, bias=False)\n",
       "    (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1_1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (conv1x1_2): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block1_2): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=8, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=8, bias=False)\n",
       "    (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block2_1): TransitionBlock(\n",
       "    (freq_dw_conv): Conv2d(12, 12, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0), dilation=(1, 2), groups=12, bias=False)\n",
       "    (ssn): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(12, 12, kernel_size=(1, 3), stride=(2, 1), padding=(0, 2), dilation=(1, 2), groups=12, bias=False)\n",
       "    (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1_1): Conv2d(8, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (conv1x1_2): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block2_2): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(12, 12, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 2), groups=12, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(12, 12, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2), dilation=(1, 2), groups=12, bias=False)\n",
       "    (bn): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block3_1): TransitionBlock(\n",
       "    (freq_dw_conv): Conv2d(20, 20, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0), dilation=(1, 4), groups=20, bias=False)\n",
       "    (ssn): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(20, 20, kernel_size=(1, 3), stride=(2, 1), padding=(0, 4), dilation=(1, 4), groups=20, bias=False)\n",
       "    (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1_1): Conv2d(12, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (conv1x1_2): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block3_2): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 4), groups=20, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=(0, 4), dilation=(1, 4), groups=20, bias=False)\n",
       "    (bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block3_3): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 4), groups=20, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=(0, 4), dilation=(1, 4), groups=20, bias=False)\n",
       "    (bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block3_4): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 4), groups=20, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=(0, 4), dilation=(1, 4), groups=20, bias=False)\n",
       "    (bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block4_1): TransitionBlock(\n",
       "    (freq_dw_conv): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 8), groups=20, bias=False)\n",
       "    (ssn): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=(0, 8), dilation=(1, 8), groups=20, bias=False)\n",
       "    (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1_1): Conv2d(16, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (conv1x1_2): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block4_2): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 8), groups=20, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=(0, 8), dilation=(1, 8), groups=20, bias=False)\n",
       "    (bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block4_3): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 8), groups=20, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=(0, 8), dilation=(1, 8), groups=20, bias=False)\n",
       "    (bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block4_4): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 8), groups=20, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=(0, 8), dilation=(1, 8), groups=20, bias=False)\n",
       "    (bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (conv_block1): ConvBlock(\n",
       "    (conv1): Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block2): ConvBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block3): ConvBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block4): ConvBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc_audioset): Linear(in_features=512, out_features=527, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cb5c10ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SHAPE: torch.Size([1, 1, 40, 1001])\n",
      "BLOCK1 INPUT SHAPE: torch.Size([1, 16, 20, 1001])\n",
      "BLOCK2 INPUT SHAPE: torch.Size([1, 8, 20, 1001])\n",
      "BLOCK3 INPUT SHAPE: torch.Size([1, 12, 10, 1001])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (256x1x250). Calculated output size: (256x0x125). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-77f923347ad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-f8e9a321a9fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, mixup_lambda)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-2814a848bfdc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, pool_size, pool_type)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpool_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpool_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg+max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (256x1x250). Calculated output size: (256x0x125). Output size is too small"
     ]
    }
   ],
   "source": [
    "out=model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "77aafb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 320000])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc232b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 527])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['clipwise_output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66958712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d12990a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5960559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b0aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f055f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287ce88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "04cce1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    " \n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "    \n",
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "                              \n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "                              \n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "\n",
    "        \n",
    "    def forward(self, input, pool_size=(1, 1), pool_type='max'):\n",
    "        \n",
    "        x = input\n",
    "        x = F.relu_(self.bn1(self.conv1(x)))\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        if pool_type == 'max':\n",
    "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg':\n",
    "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg+max':\n",
    "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
    "            x = x1 + x2\n",
    "        else:\n",
    "            raise Exception('Incorrect argument!')\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c96e4385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn10(nn.Module):\n",
    "    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, \n",
    "        fmax, classes_num):\n",
    "        \n",
    "        super(Cnn10, self).__init__()\n",
    "\n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
    "            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
    "            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "            freq_drop_width=8, freq_stripes_num=2)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(40)\n",
    "\n",
    "        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n",
    "        self.conv_block2 = ConvBlock(in_channels=64, out_channels=128)\n",
    "        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n",
    "        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n",
    "\n",
    "        self.fc1 = nn.Linear(512, 512, bias=True)\n",
    "        self.fc_audioset = nn.Linear(512, classes_num, bias=True)\n",
    "        \n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc_audioset)\n",
    " \n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"\n",
    "        Input: (batch_size, data_length)\"\"\"\n",
    "\n",
    "        x = self.spectrogram_extractor(input)   # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "        \n",
    "        if self.training:\n",
    "            x = self.spec_augmenter(x)\n",
    "\n",
    "        # Mixup on spectrogram\n",
    "        #if self.training and mixup_lambda is not None:\n",
    "        #    x = do_mixup(x, mixup_lambda)\n",
    "        \n",
    "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        \n",
    "        (x1, _) = torch.max(x, dim=2)\n",
    "        x2 = torch.mean(x, dim=2)\n",
    "        x = x1 + x2\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        embedding = F.dropout(x, p=0.5, training=self.training)\n",
    "        clipwise_output = torch.sigmoid(self.fc_audioset(x))\n",
    "        \n",
    "        output_dict = {'clipwise_output': clipwise_output, 'embedding': embedding}\n",
    "\n",
    "        return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1b84256",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Cnn10(sample_rate=32000, window_size=1024, \n",
    "        hop_size=320, classes_num=527,mel_bins=40, fmin=50, fmax=14000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b03d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample확인하기 \n",
    "import torchaudio\n",
    "x,sr=torchaudio.load(\"./datasets/audioset201906/audios/balanced_train_segments/Y0-3jSTs2Zsw.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d46d1c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 320000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "717318dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f8b9b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 527])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['clipwise_output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef3f7092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCResNet(\n",
       "  (spectrogram_extractor): Spectrogram(\n",
       "    (stft): STFT(\n",
       "      (conv_real): Conv1d(1, 513, kernel_size=(1024,), stride=(320,), bias=False)\n",
       "      (conv_imag): Conv1d(1, 513, kernel_size=(1024,), stride=(320,), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (logmel_extractor): LogmelFilterBank()\n",
       "  (spec_augmenter): SpecAugmentation(\n",
       "    (time_dropper): DropStripes()\n",
       "    (freq_dropper): DropStripes()\n",
       "  )\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(2, 1), padding=(2, 2))\n",
       "  (block1_1): TransitionBlock(\n",
       "    (freq_dw_conv): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=8, bias=False)\n",
       "    (ssn): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=8, bias=False)\n",
       "    (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1_1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (conv1x1_2): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block1_2): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=8, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=8, bias=False)\n",
       "    (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block2_1): TransitionBlock(\n",
       "    (freq_dw_conv): Conv2d(12, 12, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0), dilation=(1, 2), groups=12, bias=False)\n",
       "    (ssn): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(12, 12, kernel_size=(1, 3), stride=(2, 1), padding=(0, 2), dilation=(1, 2), groups=12, bias=False)\n",
       "    (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1_1): Conv2d(8, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (conv1x1_2): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block2_2): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(12, 12, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 2), groups=12, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(12, 12, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2), dilation=(1, 2), groups=12, bias=False)\n",
       "    (bn): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block3_1): TransitionBlock(\n",
       "    (freq_dw_conv): Conv2d(16, 16, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0), dilation=(1, 4), groups=16, bias=False)\n",
       "    (ssn): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(16, 16, kernel_size=(1, 3), stride=(2, 1), padding=(0, 4), dilation=(1, 4), groups=16, bias=False)\n",
       "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1_1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (conv1x1_2): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block3_2): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 4), groups=16, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 4), dilation=(1, 4), groups=16, bias=False)\n",
       "    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block3_3): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 4), groups=16, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 4), dilation=(1, 4), groups=16, bias=False)\n",
       "    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block3_4): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 4), groups=16, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 4), dilation=(1, 4), groups=16, bias=False)\n",
       "    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block4_1): TransitionBlock(\n",
       "    (freq_dw_conv): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 8), groups=20, bias=False)\n",
       "    (ssn): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=(0, 8), dilation=(1, 8), groups=20, bias=False)\n",
       "    (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1_1): Conv2d(16, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (conv1x1_2): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block4_2): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 8), groups=20, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=(0, 8), dilation=(1, 8), groups=20, bias=False)\n",
       "    (bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block4_3): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 8), groups=20, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=(0, 8), dilation=(1, 8), groups=20, bias=False)\n",
       "    (bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (block4_4): BroadcastedBlock(\n",
       "    (freq_dw_conv): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=(1, 8), groups=20, bias=False)\n",
       "    (ssn1): SubSpectralNorm(\n",
       "      (bn): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (temp_dw_conv): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=(0, 8), dilation=(1, 8), groups=20, bias=False)\n",
       "    (bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (channel_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (swish): SiLU()\n",
       "    (conv1x1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1), padding=(0, 2), groups=20)\n",
       "  (conv3): Conv2d(20, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (conv4): Conv2d(32, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (fc1): Linear(in_features=1, out_features=2048, bias=True)\n",
       "  (fc_audioset): Linear(in_features=2048, out_features=527, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ad0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ecaa3956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SHAPE: torch.Size([1, 1, 1001, 64])\n",
      "BLOCK1 INPUT SHAPE: torch.Size([1, 16, 501, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 40, 100, 64]' is invalid for input of size 256512",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-bd0200007a4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-b4b889acda15>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, mixup_lambda)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BLOCK1 INPUT SHAPE:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-b4b889acda15>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq_dw_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m#############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mauxilary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-b4b889acda15>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# S: number of sub-bands\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 40, 100, 64]' is invalid for input of size 256512"
     ]
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d52db386",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate=32000\n",
    "window_size=1024 \n",
    "hop_size=320\n",
    "mel_bins=64\n",
    "fmin=50\n",
    "fmax=14000\n",
    "window='han'\n",
    "center=True\n",
    "pad_mode='reflect'\n",
    "ref = 1.0\n",
    "amin = 1e-10\n",
    "top_db = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "97d26323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram extractor\n",
    "spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
    "            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
    "            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "            freq_drop_width=8, freq_stripes_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4a6d2653",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=spectrogram_extractor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "05aded32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1001, 513])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bb769ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = logmel_extractor(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "32e3243b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1001, 64])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b5a7b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.transpose(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d1956a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 1001, 1])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9cc68df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.transpose(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bae2df68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1001, 64])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6a19ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.transpose(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3a1b4fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 1001])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37898522",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = self.spectrogram_extractor(input)\n",
    "        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
    "        x = x.transpose(1, 3)\n",
    "        #x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "        \n",
    "        if self.training:\n",
    "            x = self.spec_augmenter(x)\n",
    "\n",
    "        # Mixup on spectrogram\n",
    "        if self.training and mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "        \n",
    "        print('INPUT SHAPE:', x.shape)\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        print('BLOCK1 INPUT SHAPE:', out.shape)\n",
    "        out = self.block1_1(out)\n",
    "        out = self.block1_2(out)\n",
    "\n",
    "        print('BLOCK2 INPUT SHAPE:', out.shape)\n",
    "        out = self.block2_1(out)\n",
    "        out = self.block2_2(out)\n",
    "\n",
    "        print('BLOCK3 INPUT SHAPE:', out.shape)\n",
    "        out = self.block3_1(out)\n",
    "        out = self.block3_2(out)\n",
    "        out = self.block3_3(out)\n",
    "        out = self.block3_4(out)\n",
    "\n",
    "        print('BLOCK4 INPUT SHAPE:', out.shape)\n",
    "        out = self.block4_1(out)\n",
    "        out = self.block4_2(out)\n",
    "        out = self.block4_3(out)\n",
    "        out = self.block4_4(out)\n",
    "\n",
    "        print('Conv2 INPUT SHAPE:', out.shape)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        print('Conv3 INPUT SHAPE:', out.shape)\n",
    "        out = self.conv3(out)\n",
    "        out = out.mean(-1, keepdim=True)\n",
    "\n",
    "        print('Conv4 INPUT SHAPE:', out.shape)\n",
    "        out = self.conv4(out)\n",
    "\n",
    "        print('OUTPUT SHAPE:', out.shape)\n",
    "        (x1, _) = torch.max(out, dim=2)\n",
    "        x2 = torch.mean(out, dim=2)\n",
    "        x = x1 + x2\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        out = F.relu_(self.fc1(x))\n",
    "        embedding = F.dropout(out, p=0.5, training=self.training)\n",
    "        clipwise_output = torch.sigmoid(self.fc_audioset(out))\n",
    "        output_dict = {'clipwise_output': clipwise_output, 'embedding': embedding}\n",
    "        #print('OUTPUT SHAPE:', out.shape)\n",
    "        return output_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
